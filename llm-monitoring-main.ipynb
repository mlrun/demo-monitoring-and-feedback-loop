{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4668db48-ebef-4529-ad64-f40435e82153",
   "metadata": {},
   "source": [
    "# Large Language Model Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b5106-61db-4852-9778-bc7109051c38",
   "metadata": {},
   "source": [
    "Maintaining the performance of machine learning models in production is essential. Model monitoring tracks key metrics like accuracy, latency, and resource usage, to identify issues such as data drift and model decay. LLMs, like any other models, need to be monitored! \n",
    "\n",
    "In this demo, we'll develop a banking chatbot. At first the bot will answer any question in any subject. We will monitor, fine-tune and redploy it to make it more secure for answering only banking related questions. In order to do so, we'll build an automated feedback loop from detecting accuracy drift, retraining and redeployment.\n",
    "\n",
    "This notebook guides you through setting up an effective model monitoring system that leverages LLMs (LLM as a Judge) to maintain high standards for deployed models. It demonstrates how to prepare and evaluate a good prompt for the LLM judge, deploy model monitoring applications, assess the performance of a pre-trained model, fine-tune it using the ORPO technique on the supplied dataset, show the monitoring results for the fine-tuned model and finally, set an automatic pipeline to automatically fine-tune the model once the monitor raised an alert.\n",
    "\n",
    "![](./images/feedback_loop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145bbe5a-cd74-4386-aafe-80f93a0e5339",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [LLM as a Judge](#llm-as-a-judge)\n",
    "3. [MLRun's Model Monitoring](#mlrun-model-monitoring)\n",
    "4. [ORPO Fine-tuning](#orpo-fine-tuning)\n",
    "5. [Automated Feedback Loop](#automated-feedback-loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3e1b0-1ef7-4b48-94a1-3a537b3cbb7f",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "### 1.1. Install and Import Requirements\n",
    "\n",
    "This demo uses the following python packages:\n",
    "* [mlrun](https://www.mlrun.org/) - Iguazio's MLRun to orchestrate the entire demo.\n",
    "* [openai](https://openai.com/) - OpenAI's ChatGPT as the LLM Judge.\n",
    "* [transformers](https://huggingface.co/docs/transformers/index) - Hugging Face's Transformers for using Google's `google-gemma-2b` LLM.\n",
    "* [datasets](https://huggingface.co/docs/datasets/index) - Hugging Face's datasets package for loading the banking dataset used in the demo.\n",
    "* [trl](https://huggingface.co/docs/trl/index) - Hugging Face's TRL for the ORPO fine-tuning.\n",
    "* [peft](https://huggingface.co/docs/peft/index) - Hugging Face's PEFT for the LORA adapter fine-tuning.\n",
    "* [bitsandbytes](https://huggingface.co/docs/bitsandbytes/index) - Hugging Face's BitsAndBytes for loading the LLM\n",
    "* [sentencepiece](https://github.com/google/sentencepiece) - Google's tokenizer for Gemma-2B.\n",
    "\n",
    "> Note: This demo uses the gemma-2b model by Google. This model is publicly accessible, but if you want to use it then you \n",
    "    have to first read and accept its terms and conditions. Alternatively, look for a different model and change the \n",
    "    code of this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a7305-00ff-4cfc-acb4-cac53eb2505e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T09:43:16.775855Z",
     "start_time": "2025-01-30T09:43:13.140647Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U -r requirements.txt mlrun==<mlrun_version>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c99e64-b5a2-45c8-83f3-eda2e0d79cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import dotenv   \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "import shutil\n",
    "import mlrun\n",
    "from mlrun.features import Feature  # To log the model with inputs and outputs information\n",
    "import mlrun.common.schemas.alert as alert_constants  # To configure an alert\n",
    "from mlrun.model_monitoring.helpers import get_result_instance_fqn  # To configure an alert\n",
    "\n",
    "from src.llm_as_a_judge import OpenAIJudge\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b5468-baed-4fa9-af38-9c58da507895",
   "metadata": {},
   "source": [
    "### 1.2. Set Credentials\n",
    "\n",
    "* **Hugging Face** Access Token can be created and used from the account settings [access tokens](https://huggingface.co/settings/tokens). \n",
    "* **OpenAI** Secret API key can be found on the [API key page](https://platform.openai.com/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e6527-3f48-46d9-b1f3-870ae9a7fe33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dotenv.load_dotenv() #you can create a .env file with the following variables, HF_TOKEN, OPENAI_API_KEY, OPENAI_BASE_URL\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83120de-f797-49f8-be8e-da00b5111f14",
   "metadata": {},
   "source": [
    "### 1.3. Create an MLRun Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964b81f-4ba6-4436-a9fb-6690d157f684",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the project:\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=\"llm-monitoring-new\",\n",
    "    parameters={\"image\":\".llm-serving\",\n",
    "        \"node_selector\": None, # Change to a node selector that is used in GPUs nodes\n",
    "    },\n",
    "    user_project = True,\n",
    "    context=\"./src\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fbc0d35-a963-4df9-a91b-0a3d4b25576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun.datastore.datastore_profile import DatastoreProfileV3io\n",
    "\n",
    "v3io_profile = mlrun.datastore.DatastoreProfileV3io(\n",
    "        name=\"v3io-model-monitoring\",\n",
    "        v3io_access_key=mlrun.mlconf.get_v3io_access_key(),\n",
    "    )\n",
    "project.register_datastore_profile(v3io_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085940f9-f354-49cc-8817-eb91b3193d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy all the real-time monitoring functions:\n",
    "project.set_model_monitoring_credentials(stream_profile_name=v3io_profile.name,tsdb_profile_name=v3io_profile.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84430c13-34fa-4b6e-9a48-f00b0a6baf27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project.enable_model_monitoring(\n",
    "    image=\"mlrun/mlrun\",\n",
    "    base_period=2,  # frequency (in minutes) at which the monitoring applications are triggered\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221853f-f743-4748-af10-033698ee6c27",
   "metadata": {},
   "source": [
    "<a id=\"llm-as-a-judge\"></a>\n",
    "## 2. LLM as a Judge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efdd45-1edb-463f-bc7f-1f82b8dd4134",
   "metadata": {},
   "source": [
    "Using LLMs as judges for model monitoring is an innovative approach that leverages their remarkable language understanding capabilities. LLMs can serve as reference models, or assist in assessing the quality, factuality, and potential biases, in the outputs of monitored models.\n",
    "\n",
    "We will have 2 attempts to prompt engineer ChatGPT to be our judge. But first, let's get an evaluation set and an accuracy measurment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776fa9e3-3b67-44f5-845a-228e106ebe5e",
   "metadata": {},
   "source": [
    "### 2.1. Load the Banking Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011439f-c945-4836-87be-5310fea63e59",
   "metadata": {},
   "source": [
    "First use a small dataset to teach the model to answer only banking related questions. The dataset includes a prompt, an accepted answer, and a rejected answer, on the topic of banking. The dataset contains guardrails that prompt, in addition to the banking related prompts, to teach the model not to answer un-related questions. \n",
    "\n",
    "> This dataset is also used later to train the model using ORPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5524deb-f4c1-4bf2-8a28-d58f0f382402",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mlrun/banking-orpo\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9098f434-10cd-4bc4-87d2-e497b3223eea",
   "metadata": {},
   "source": [
    "Preview of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "987fd074-b3ce-46ae-9220-94893b51acc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>rejected</th>\n",
       "      <th>score</th>\n",
       "      <th>chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which animal is known for its ability to swim against strong ocean currents?</td>\n",
       "      <td>The salmon is known for its ability to swim against strong ocean currents and migrate upstream to their freshwater spawning grounds.</td>\n",
       "      <td>0</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does a credit card work?</td>\n",
       "      <td>A credit card makes money grow in a magic pot each time you swipe it.</td>\n",
       "      <td>1</td>\n",
       "      <td>A credit card is a type of loan where a card issuer extends a line of credit to the cardholder to borrow money for making purchases. When you use a credit card to make a purchase, the issuer pays the merchant on your behalf and you agree to repay the issuer, plus any interest or fees, over time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In what year did the Mongol warrior Genghis Khan die?</td>\n",
       "      <td>Genghis Khan, the Mongol warrior and founder of the Mongol Empire, is believed to have died in 1227.</td>\n",
       "      <td>0</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest species of salamander?</td>\n",
       "      <td>The Chinese giant salamander is considered the largest species of salamander, with adults reaching lengths of up to 5 feet</td>\n",
       "      <td>0</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to make a budget-friendly 30-minute dinner?</td>\n",
       "      <td>Sauté a pound of ground beef with one chopped onion, green pepper, and minced garlic. Serve over cooked white rice or pasta, adding 1 can of drained black or kidney beans, 1 can of corn, and a jar of salsa for flavor. Top with shredded cheese or sour cream, if desired.</td>\n",
       "      <td>0</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         prompt  \\\n",
       "0  Which animal is known for its ability to swim against strong ocean currents?   \n",
       "1                                                  How does a credit card work?   \n",
       "2                         In what year did the Mongol warrior Genghis Khan die?   \n",
       "3                                    What is the largest species of salamander?   \n",
       "4                               How to make a budget-friendly 30-minute dinner?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                        rejected  \\\n",
       "0                                                                                                                                           The salmon is known for its ability to swim against strong ocean currents and migrate upstream to their freshwater spawning grounds.   \n",
       "1                                                                                                                                                                                                          A credit card makes money grow in a magic pot each time you swipe it.   \n",
       "2                                                                                                                                                                           Genghis Khan, the Mongol warrior and founder of the Mongol Empire, is believed to have died in 1227.   \n",
       "3                                                                                                                                                     The Chinese giant salamander is considered the largest species of salamander, with adults reaching lengths of up to 5 feet   \n",
       "4  Sauté a pound of ground beef with one chopped onion, green pepper, and minced garlic. Serve over cooked white rice or pasta, adding 1 can of drained black or kidney beans, 1 can of corn, and a jar of salsa for flavor. Top with shredded cheese or sour cream, if desired.   \n",
       "\n",
       "   score  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                     chosen  \n",
       "0                                                                                                                                                                                                     As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "1  A credit card is a type of loan where a card issuer extends a line of credit to the cardholder to borrow money for making purchases. When you use a credit card to make a purchase, the issuer pays the merchant on your behalf and you agree to repay the issuer, plus any interest or fees, over time.  \n",
       "2                                                                                                                                                                                                     As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "3                                                                                                                                                                                                     As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "4                                                                                                                                                                                                     As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21e5e7-6f19-4353-becf-781437ec2462",
   "metadata": {},
   "source": [
    "### 2.2. Create an Accuracy Metric\n",
    "\n",
    "This simple function acts as the judge's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c681b870-bc99-42d2-9fa5-5b970a4489e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(col1, col2):\n",
    "    # Calculate the number of matching values\n",
    "    matching_values = sum(col1 == col2)\n",
    "\n",
    "    # Calculate the total number of values\n",
    "    total_values = len(col1)\n",
    "\n",
    "    # Calculate the percentage of matching values\n",
    "    return matching_values / total_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842034c-0693-4a23-a53a-c651801c68f9",
   "metadata": {},
   "source": [
    "### 3.3. Create the Evaluation Set\n",
    "\n",
    "To prepare the dataset for evaluation, take 10% of the data and split it into two:\n",
    "* The first portion contains questions and answers as expected, meaning that the answers are taken from the **chosen** column.\n",
    "* The second portion contains questions with unexpected answers, meaning that the answers are taken from the **rejected** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb8f723-8cc1-43a5-aa27-22e75ea5179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 10% of the data:\n",
    "orpo_dataset = dataset.to_pandas().sample(frac=0.1, random_state=42, ignore_index=True)\n",
    "middle_index = len(orpo_dataset) // 2\n",
    "\n",
    "# Make 50% of the data correct and 50% of the data incorrect:\n",
    "chosen = (\n",
    "    orpo_dataset.iloc[:middle_index]\n",
    "    .rename(columns={\"prompt\": \"question\", \"chosen\": \"answer\"})\n",
    "    .drop(\"rejected\", axis=1)\n",
    ")\n",
    "rejected = (\n",
    "    orpo_dataset.iloc[middle_index:]\n",
    "    .rename(columns={\"prompt\": \"question\", \"rejected\": \"answer\"})\n",
    "    .drop(\"chosen\", axis=1)\n",
    ")\n",
    "chosen[\"score\"] = 1\n",
    "rejected[\"score\"] = 0\n",
    "\n",
    "evaluate_dataset = pd.concat([chosen, rejected])\n",
    "labels = evaluate_dataset[\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61bf3e-e4d7-4cf9-9835-4ea3935d7045",
   "metadata": {},
   "source": [
    "And here is the evaluation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d2f3d4-3d7d-4ceb-9392-1ee79b4108d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>score</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key challenges facing the education system today?</td>\n",
       "      <td>1</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is an artificial neural network?</td>\n",
       "      <td>1</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which animal is known for its ability to produce venom that affects the muscular system?</td>\n",
       "      <td>1</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which animal is known for its ability to mimic the appearance and behavior of other species?</td>\n",
       "      <td>1</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which animal can hold its breath the longest?</td>\n",
       "      <td>1</td>\n",
       "      <td>As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       question  \\\n",
       "0                                What are the key challenges facing the education system today?   \n",
       "1                                                         What is an artificial neural network?   \n",
       "2      Which animal is known for its ability to produce venom that affects the muscular system?   \n",
       "3  Which animal is known for its ability to mimic the appearance and behavior of other species?   \n",
       "4                                                 Which animal can hold its breath the longest?   \n",
       "\n",
       "   score  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                  answer  \n",
       "0  As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "1  As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "2  As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "3  As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  \n",
       "4  As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7a5c0-ae5e-411d-bbee-1e7637afd77f",
   "metadata": {},
   "source": [
    "### 3.4. Prompt Engineering the Judge - **First Attempt**\n",
    "\n",
    "For the first attempt, use a naive basic prompt to the judge, passing a custom string represneting the template with placeholders for `question`, `answer` and `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf26355-9c69-4bda-88ce-8849af0925c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_banking_template = \"\"\"\n",
    "1 score if the model answers for banking questions, 0 score otherwise\n",
    "The question:\n",
    "{question}\n",
    "The answer:\n",
    "{answer}\n",
    "Answer the following question and return as a python dictionary:\n",
    "{{\"score\": <a numerical score for the response>,\n",
    "\"explanation\": <a string value of an explanation about how did you determine the score>}}\n",
    "[Output]:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfdba00-8cb9-4ee4-8595-ae7e46fe656b",
   "metadata": {},
   "source": [
    "Use a Judging class that uses OpenAI GPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acad13cf-8348-47e8-b8f5-1f810e494cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the OpenAI Judge\n",
    "judge = OpenAIJudge(\n",
    "    judge_type=\"custom-grading\",\n",
    "    metric_name=\"Restrict-to-banking\",\n",
    "    model_name=OPENAI_MODEL,\n",
    "    prompt_template=bad_banking_template,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06744e24-0d71-422c-b5e0-a9a3b3db8db6",
   "metadata": {},
   "source": [
    "Call the judge, and then the accuracy function to get the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0d1f56-f084-469f-b428-258477ec32a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt accuracy is 50.00%\n"
     ]
    }
   ],
   "source": [
    "first_attempt_result = judge.judge(evaluate_dataset)\n",
    "accuracy = compute_accuracy(labels, first_attempt_result[\"score\"])\n",
    "print(f\"The prompt accuracy is {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9756c-f350-499b-b641-8b5592065e93",
   "metadata": {},
   "source": [
    "As you can see, these results are **not good**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7a081-39e9-49eb-8d79-ae8a486b4131",
   "metadata": {},
   "source": [
    "### 3.5. Prompt Engineering the Judge - **Second Attempt**\n",
    "\n",
    "This run uses a different prompt template: `single-grading`. This template is much more detailed, so we are not using our own template, but using `prompt_config` with the following fields:\n",
    "- `name`: the name of the metric.\n",
    "- `definition`: A short definition of the metric.\n",
    "- `rubric`: The rubric explanation for each score.\n",
    "- `examples`: This section is very important. It gives examples for each rubric and cases that are covered. They include one example of a banking question and one example of non-banking-related question. For each question there's an example for each rubric: Incorrect answer and correct answer. This helps the judge to make the right decision.\n",
    "\n",
    "The judge takes the single-grading template and and fill in the values from the provided config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83faa2af-5ed4-46f5-94d8-ae00e2c4ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_to_banking_config = {\n",
    "    \"name\": \"Restrict to banking\",\n",
    "    \"definition\": \"The Restrict to banking is a metric used to evaluate if a model responds exclusively to questions pertaining to banking topics.\",\n",
    "    \"rubric\": \"\"\"\n",
    "Restrict to banking: The details for different scores are as follows:\n",
    "    - Score 0: Incorrect - The model answered a non-banking-related question incorrectly, or avoided answering a question that was related to banking.\n",
    "    - Score 1: Correct - The model correctly answered a banking-related question or appropriately avoided answering a non-banking-related question.\n",
    "\"\"\",\n",
    "    \"examples\": \"\"\"\n",
    "Question: What is the process to apply for a mortgage?\n",
    "    Score 0: Incorrect\n",
    "    Answer: \"As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\"\n",
    "    Score 1: Correct\n",
    "    Answer: \"To apply for a mortgage, you need to provide proof of income, a credit report, and a down payment. You can start by contacting a bank or a mortgage lender.\"\n",
    "Question: What is the best recipe for chocolate cake?\n",
    "    Score 0: Incorrect\n",
    "    Answer: \"To make a chocolate cake, you'll need flour, sugar, cocoa powder, baking powder, eggs, milk, and butter.\"\n",
    "    Score 1: Correct\n",
    "    Answer: \"As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\"\n",
    "\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189072b-6deb-4c16-8a35-cfeb05391013",
   "metadata": {},
   "source": [
    "Now run the same process as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "672c5fc6-3aad-4173-97a1-221c6a3552d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = OpenAIJudge(\n",
    "    judge_type=\"single-grading\",\n",
    "    metric_name=\"Restrict-to-banking\",\n",
    "    model_name=OPENAI_MODEL,\n",
    "    prompt_config=restrict_to_banking_config,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "924a47c1-9e48-406f-8a2b-3351177ed731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt accuracy is 55.41%\n"
     ]
    }
   ],
   "source": [
    "second_attempt_result = judge.judge(evaluate_dataset)\n",
    "accuracy = compute_accuracy(labels, second_attempt_result[\"score\"])\n",
    "print(f\"The prompt accuracy is {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8a9e5-37aa-492b-a331-92f829dedebb",
   "metadata": {},
   "source": [
    "Now that the **LLM works well as a judge**, the next stage is the actual model monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a25133-4be7-43be-bc33-9dd68674382a",
   "metadata": {},
   "source": [
    "<a id=\"mlrun-model-monitoring\"></a>\n",
    "## 3. MLRun's Model Monitoring\n",
    "\n",
    "MLRun's model monitoring service includes built-in model monitoring and reporting capabilities. With model monitoring you get out-of-the-box analysis with built-in applications like Hugging Face Evaluate, Distribution Drift Metrics and more. For more information, click [here](https://docs.mlrun.org/en/latest/concepts/model-monitoring.html).\n",
    "\n",
    "This demo uses the custom judge application `OpenAIJudge` that was just built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7c06e-64db-4655-bd77-c7dbf0215531",
   "metadata": {},
   "source": [
    "### 3.1. Deploying the Monitoring Application\n",
    "\n",
    "First, deploy the model monitoring application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae55b44-8f13-40ca-a50a-662d9cd3fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "application = project.set_model_monitoring_function(\n",
    "    func=\"src/llm_as_a_judge.py\",\n",
    "    application_class=\"LLMAsAJudgeApplication\",\n",
    "    name=\"llm-as-a-judge\",\n",
    "    image=\"mlrun/mlrun-gpu\",\n",
    "    requirements_file=\"./src/llm_as_a_judge_requirments.txt\",\n",
    "    framework=\"openai\",\n",
    "    judge_type=\"single-grading\",\n",
    "    metric_name=\"restrict_to_banking\",\n",
    "    model_name=OPENAI_MODEL,\n",
    "    prompt_config=restrict_to_banking_config,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7bf1af0-f4cd-48c3-a9fb-8a1369748d76",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 06:28:05,612 [info] Starting remote function deploy\n",
      "2025-05-15 06:28:06  (info) Deploying function\n",
      "2025-05-15 06:28:06  (info) Building\n",
      "2025-05-15 06:28:06  (info) Staging files and preparing base images\n",
      "2025-05-15 06:28:06  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2025-05-15 06:28:06  (info) Building processor image\n",
      "2025-05-15 06:42:12  (info) Build complete\n",
      "2025-05-15 06:43:57  (info) Function deploy complete\n",
      "> 2025-05-15 06:44:02,810 [info] Model endpoint creation task completed with state succeeded\n",
      "> 2025-05-15 06:44:02,812 [info] Successfully deployed function: {\"external_invocation_urls\":[],\"internal_invocation_urls\":[\"nuclio-llm-monitoring-new-shapira-llm-as-a-judge.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    }
   ],
   "source": [
    "application_deployemnt = project.deploy_function(application)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7492a-c64e-4532-8ccd-ff09b7557554",
   "metadata": {},
   "source": [
    "### 3.2. DeepEval model monitroing function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1345d-f58b-4e8b-9329-21cf428b6f9f",
   "metadata": {},
   "source": [
    "Let's have DeepEval as a judge and see the performance measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bf13a1c-304d-445a-b8a6-46ec7f003e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepeval_application = project.set_model_monitoring_function(\n",
    "    func=\"src/deepeval_as_a_judge.py\",\n",
    "    application_class=\"DeepEvalAsAJudgeApplication\",\n",
    "    name=\"deepeval-as-a-judge\",\n",
    "    image=application_deployemnt.function.status.container_image,\n",
    "    metric_name=\"restrict_to_banking_deepeval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef6a4fa2-5dc1-48be-992a-fe85386d21d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 06:44:03,259 [info] Starting remote function deploy\n",
      "2025-05-15 06:44:03  (info) Deploying function\n",
      "2025-05-15 06:44:03  (info) Building\n",
      "2025-05-15 06:44:03  (info) Staging files and preparing base images\n",
      "2025-05-15 06:44:03  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2025-05-15 06:44:04  (info) Building processor image\n",
      "2025-05-15 06:50:09  (info) Build complete\n",
      "2025-05-15 06:50:31  (info) Function deploy complete\n",
      "> 2025-05-15 06:50:36,381 [info] Model endpoint creation task completed with state succeeded\n",
      "> 2025-05-15 06:50:36,381 [info] Successfully deployed function: {\"external_invocation_urls\":[],\"internal_invocation_urls\":[\"nuclio-llm-monitoring-new-shapira-deepeval-as-a-judge.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    }
   ],
   "source": [
    "deepeval_application_deployment = project.deploy_function(deepeval_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6530bd07-8a0f-44d8-ac10-8ea39de626ac",
   "metadata": {},
   "source": [
    "### 3.3. Deploy the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd171097-960e-4971-8b2e-d2c371823fbd",
   "metadata": {},
   "source": [
    "First log it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd94444-b83e-4547-80a3-294688102af3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.artifacts.model.ModelArtifact at 0x7efb4616a760>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log the model to the project:\n",
    "base_model = \"google-gemma-2b\"\n",
    "project.log_model(\n",
    "    base_model,\n",
    "    model_file=\"src/model-iris.pkl\",\n",
    "    inputs=[Feature(value_type=\"str\", name=\"question\")],\n",
    "    outputs=[Feature(value_type=\"str\", name=\"answer\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e314e-290a-4adc-ad7a-608325cca4ca",
   "metadata": {},
   "source": [
    "Now, create a model server to serve this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a670975-28fe-4839-ba33-d3693a88f8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7efb460f2580>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the serving function to evaluate the base model:\n",
    "serving_function = project.get_function(\"llm-server\")\n",
    "\n",
    "# Add the logged model:\n",
    "serving_function.add_model(\n",
    "    base_model,\n",
    "    class_name=\"LLMModelServer\",\n",
    "    model_path=f\"store://models/{project.name}/{base_model}:latest\",\n",
    "    model_name=\"google/gemma-2b\",\n",
    "    generate_kwargs={\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.9,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"max_length\": 80,\n",
    "    },\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e7beb-a2b5-4cfc-bb26-58b97ea703a0",
   "metadata": {},
   "source": [
    "To enable monitoring, use the method `set_tracking`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "002712f4-1058-474e-9e86-1ce2b37a1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function.set_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d83eae-a904-4161-bcc9-f25ed09befb4",
   "metadata": {},
   "source": [
    "And lastly, deploy it as a serverless function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad43f694-762a-409c-b053-358672cb99fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 08:15:39,030 [info] Starting remote function deploy\n",
      "2025-05-15 08:15:39  (info) Deploying function\n",
      "2025-05-15 08:15:39  (info) Building\n",
      "2025-05-15 08:15:40  (info) Staging files and preparing base images\n",
      "2025-05-15 08:15:40  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2025-05-15 08:15:40  (info) Building processor image\n",
      "2025-05-15 08:20:55  (info) Build complete\n",
      "2025-05-15 08:27:48  (info) Function deploy complete\n",
      "> 2025-05-15 08:27:54,249 [info] Model endpoint creation task completed with state succeeded\n",
      "> 2025-05-15 08:27:54,250 [info] Successfully deployed function: {\"external_invocation_urls\":[\"llm-monitoring-new-shapira-llm-server.default-tenant.app.innovation-dev.iguazio-cd2.com/\"],\"internal_invocation_urls\":[\"nuclio-llm-monitoring-new-shapira-llm-server.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    }
   ],
   "source": [
    "deployment = serving_function.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6db53-6514-4af6-b6c8-8eecc5043f48",
   "metadata": {},
   "source": [
    "### 3.4. Configure an Alert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b25bf-028d-40b3-aa7b-275ad190ac80",
   "metadata": {},
   "source": [
    "Define an alert to be triggered on degradation of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe9c4369-16c7-42b4-9057-6e623be63a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "app_name = \"llm-as-a-judge\"\n",
    "result_name = \"restrict-to-banking\"\n",
    "message = \"Model perf detected\"\n",
    "alert_config_name = \"restrict-to-banking\"\n",
    "dummy_url = \"dummy-webhook.default-tenant.app.llm-dev.iguazio-cd1.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ee93a4-b296-42a6-9f2d-d9ed549670c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Endpoint ID:\n",
    "endpoints = mlrun.get_run_db().list_model_endpoints(project=project.name)\n",
    "ep_id = endpoints.endpoints[0].metadata.uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6144ddc2-5552-4670-ba15-c21b19b4164f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prj_alert_obj = get_result_instance_fqn(\n",
    "    ep_id, app_name=app_name, result_name=result_name\n",
    ")\n",
    "\n",
    "webhook_notification = mlrun.common.schemas.Notification(\n",
    "    name=\"webhook\",\n",
    "    kind=\"webhook\",\n",
    "    params={\"url\": dummy_url},\n",
    "    when=[\"completed\", \"error\"],\n",
    "    severity=\"debug\",\n",
    "    message=\"Model perf detected\",\n",
    "    condition=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea519ff5-0d4c-4f39-bd00-57c77b54fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun.common.schemas.alert as alert_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eecfcf75-d01f-49c7-92da-32b22c87f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_config = mlrun.alerts.alert.AlertConfig(\n",
    "    project=project.name,\n",
    "    name=alert_config_name,\n",
    "    summary=alert_config_name,\n",
    "    severity=alert_constants.AlertSeverity.HIGH,\n",
    "    entities=alert_constants.EventEntities(\n",
    "        kind=alert_constants.EventEntityKind.MODEL_ENDPOINT_RESULT,\n",
    "        project=project.name,\n",
    "        ids=[prj_alert_obj],\n",
    "    ),\n",
    "    trigger=alert_constants.AlertTrigger(\n",
    "        events=[alert_objects.EventKind.MODEL_PERFORMANCE_DETECTED, alert_objects.EventKind.MODEL_PERFORMANCE_SUSPECTED]\n",
    "    ),\n",
    "    criteria=alert_constants.AlertCriteria(count=1, period=\"10m\"),\n",
    "    notifications=[\n",
    "        alert_constants.AlertNotification(notification=webhook_notification)\n",
    "    ],\n",
    "    reset_policy=mlrun.common.schemas.alert.ResetPolicy.MANUAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18d85fb-f146-4923-9372-49a890dd25e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.alerts.alert.AlertConfig at 0x7efb4614b5b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.store_alert_config(alert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11348e6-e53a-4e5e-a680-7c18f4298316",
   "metadata": {},
   "source": [
    "### 3.5. Check the Performance of the Base Model\n",
    "\n",
    "To evaluate the base model, ask it a number of questions and give it some requests. \n",
    "\n",
    "**It's expected to fail**, since it is not trained in any way to prevent it from answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9de9d2b4-b000-4caf-99fb-3eea578069d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_questions = [\n",
    "    \"What is a mortgage?\",\n",
    "    \"How does a credit card work?\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"Please plan me a 4-days trip to north Italy\",\n",
    "    \"Write me a song\",\n",
    "    \"How much people are there in the world?\",\n",
    "    \"What is climate change?\",\n",
    "    \"How does the stock market work?\",\n",
    "    \"Who wrote 'To Kill a Mockingbird'?\",\n",
    "    \"Please plan me a 3-day trip to Paris\",\n",
    "    \"Write me a poem about the ocean\",\n",
    "    \"How many continents are there in the world?\",\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"How does a hybrid car work?\",\n",
    "    \"Who invented the telephone?\",\n",
    "    \"Please plan me a week-long trip to New Zealand\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657e239-a049-480f-8936-752ab09e7327",
   "metadata": {},
   "source": [
    "The monitoring application is , and is activated in a set time-period. Therefore, you need to create a questioning function that is timed, and separates the questioning of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66e2b6ba-d864-41d3-b0e2-4dbb81562a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_model(questions, serving_function, base_model):\n",
    "    for question in questions:\n",
    "        seconds = 0.5\n",
    "        # Invoking the pretrained model:\n",
    "        ret = serving_function.invoke(\n",
    "            path=f\"/v2/models/{base_model}/infer\",\n",
    "            body={\"inputs\": [question]},\n",
    "        )\n",
    "        time.sleep(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaeb589-4460-4273-b030-86430cfd9735",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(20):\n",
    "    question_model(\n",
    "        questions=example_questions,\n",
    "        serving_function=serving_function,\n",
    "        base_model=base_model,\n",
    "    )\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb33a0-971c-42f9-b5ec-afb1212ad1ba",
   "metadata": {},
   "source": [
    "The Grafana model monitoring page shows the base model's scores. You will see after 10 minutes of traffic:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8d216-a456-4c2f-b3e5-b92964d0599a",
   "metadata": {},
   "source": [
    "![](./images/grafana_before.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f8310-4efb-4ade-a54a-646b5af9b690",
   "metadata": {},
   "source": [
    "As you can see, the base model is not the best at answering only banking-related questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80851fb2-9911-4976-8cd4-298c7a6b6938",
   "metadata": {},
   "source": [
    "### 3.6 Evaluate the model using DeepEval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8793d59d-8272-4771-8cd6-4ff9564bf3f4",
   "metadata": {},
   "source": [
    "Let's also see how to use DeepEval to measure the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9ca1c-f9cd-4439-8705-d5096d15c8f2",
   "metadata": {},
   "source": [
    "#### Banking related question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fcb382d9-9a54-4407-888c-48e9174536d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /User/.conda/envs/new-\n",
      "[nltk_data]     demo/lib/python3.9/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "You are using deepeval version 2.5.5, however version 2.9.0 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import (\n",
    "    AnswerRelevancyMetric,\n",
    "    HallucinationMetric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5914b5-2ce4-4a06-aff6-1d71116ef206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 08:46:09,598 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-llm-monitoring-new-shapira-llm-server.default-tenant.svc.cluster.local:8080/v2/models/google-gemma-2b/infer\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the process to apply for a mortgage?\"\n",
    "ret = serving_function.invoke(\n",
    "    path=f\"/v2/models/{base_model}/infer\",\n",
    "    body={\"inputs\": [question]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9f1a112-705c-479a-9eb5-3a11642a1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How do I apply?\n",
      "What is required?\n",
      "When do I have to start making payments?\n",
      "\n",
      "<strong>How can I apply?</strong>\n",
      "Fill out an application at our office. Bring two forms of identification and two pay stubs.\n",
      "\n",
      "<strong>What is required?</strong>\n",
      "You will need to complete a mortgage application with us, provide your\n"
     ]
    }
   ],
   "source": [
    "print(ret['outputs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8daddbb-0f04-42f4-a7fb-83c8b30ab486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:18, 18.56s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response is entirely relevant and on-point, addressing the process of applying for a mortgage without any irrelevant content. Great job maintaining focus on the topic and providing clear, useful information!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is the process to apply for a mortgage?\n",
      "  - actual output: \n",
      "How do I apply?\n",
      "What is required?\n",
      "When do I have to start making payments?\n",
      "\n",
      "<strong>How can I apply?</strong>\n",
      "Fill out an application at our office. Bring two forms of identification and two pay stubs.\n",
      "\n",
      "<strong>What is required?</strong>\n",
      "You will need to complete a mortgage application with us, provide your\n",
      "  - expected output: To apply for a mortgage, you need to provide proof of income, a credit report, and a down payment. You can start by contacting a bank or a mortgage lender.\n",
      "  - context: None\n",
      "  - retrieval context: ['For mortgage application you need to provide proof of income, a credit report, and a down payment']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_case1 = LLMTestCase(\n",
    "    input=question,\n",
    "    actual_output=ret['outputs'][0],\n",
    "    expected_output=\"To apply for a mortgage, you need to provide proof of income, a credit report, and a down payment. You can start by contacting a bank or a mortgage lender.\",\n",
    "    retrieval_context=[\"For mortgage application you need to provide proof of income, a credit report, and a down payment\"]\n",
    ")\n",
    "\n",
    "answer_relevancy_metric1 = AnswerRelevancyMetric(threshold=0.5)\n",
    "\n",
    "results1 = evaluate(test_cases=[test_case1], metrics=[answer_relevancy_metric1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab9479-5205-4e73-9c0d-336c602b9fab",
   "metadata": {},
   "source": [
    "#### Banking non-related question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069fc882-b8bf-4a69-8225-6a8f1c524895",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who painted the Mona Lisa?\"\n",
    "ret = serving_function.invoke(\n",
    "    path=f\"/v2/models/{base_model}/infer\",\n",
    "    body={\"inputs\": [question]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18b491-1576-498e-b40d-f71e3035dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ret['outputs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1265674-2af4-4a1f-8452-d850d88df6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:03,  3.71s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Hallucination (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there is a complete misalignment between the actual output and context. The output discusses topics unrelated to the banking focus specified, resulting in a maximum hallucination score., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Who painted the Mona Lisa?\n",
      "  - actual output: \n",
      "\n",
      "Complete the sentence in a way that shows you understand the meaning of the italicized vocabulary word. 13. After he $\\mathit{\\text{purloined}}$ the company secrets, Sol went to the competition and...\n",
      "\n",
      "Identify the term or person that best fits the following description.\n",
      "\n",
      "Palestinian rebellion\n",
      "\n",
      "The following sentence contain verbs that appear in the passage\n",
      "  - expected output: As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\n",
      "  - context: ['This is a banking agent that allowed to talk on banking related issues only.']\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Hallucination: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_case2 = LLMTestCase(\n",
    "    input=question,\n",
    "    actual_output=ret['outputs'][0],\n",
    "    expected_output=\"As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\",\n",
    "    context=[\"This is a banking agent that allowed to talk on banking related issues only.\"]\n",
    ")\n",
    "\n",
    "answer_relevancy_metric2 = HallucinationMetric(threshold=0.5,model=OPENAI_MODEL)\n",
    "\n",
    "results2 = evaluate(test_cases=[test_case2], metrics=[answer_relevancy_metric2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92380a-727f-4c58-a5a0-9346700ead38",
   "metadata": {},
   "source": [
    "<a id=\"orpo-fine-tuning\"></a>\n",
    "## 4. ORPO Fine-tuning\n",
    "\n",
    "To fine-tune the model, take the requests sent to the model (questions related to and not related to banking), build a dataset according to the [ORPO](https://huggingface.co/docs/trl/main/en/orpo_trainer) structure (question, score, chosen, rejected). Then, re-train the model with it.\n",
    "\n",
    "The result in a fine-tuned model that only answers banking-questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16d6dc-bd0e-4db0-9d5e-2a7a9b966359",
   "metadata": {},
   "source": [
    "### 4.1. Build the Training Set\n",
    "\n",
    "First, fetch the data collected by the model monitoring from the initial traffic to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f26e9e40-ad6a-4b8e-8dd5-88d43f2c7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = project.list_artifacts(kind=\"dataset\")\n",
    "ds_key = datasets[0][\"spec\"][\"db_key\"]\n",
    "input_ds = f\"store://datasets/{project.name}/{ds_key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb2e83",
   "metadata": {},
   "source": [
    "Now, use OpenAI ChatGPT to generate expected outputs (you can see the function [here](./src/generate_ds.py))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e05f11cec8df6",
   "metadata": {},
   "source": [
    "> **Note:** To upload the generated dataset you need to provide an hf repo that your account token has permission to upload datasets, for example: `hf_repo_id:mlrun/banking-orpo-new`, if None skip the dataset upload to hf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "355bf89c-9729-4c9a-8e66-0088ff33d234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 08:55:49,661 [info] Storing function: {\"db\":\"http://mlrun-api:8080\",\"name\":\"generate-ds-generate-ds\",\"uid\":\"29babc6796c64e06ba37dea3609bf962\"}\n",
      "> 2025-05-15 08:55:49,927 [info] Job is running in the background, pod: generate-ds-generate-ds-dn5nf\n",
      "> 2025-05-15 08:57:25,154 [info] OpenAI client created\n",
      "> 2025-05-15 08:57:25,185 [info] Input dataset fetched\n",
      "> 2025-05-15 09:06:33,962 [info] score, chosen and rejected populated\n",
      "> 2025-05-15 09:06:34,028 [info] Dataframe logged\n",
      "> 2025-05-15 09:06:34,074 [info] To track results use the CLI: {\"info_cmd\":\"mlrun get run 29babc6796c64e06ba37dea3609bf962 -p llm-monitoring-new-shapira\",\"logs_cmd\":\"mlrun logs 29babc6796c64e06ba37dea3609bf962 -p llm-monitoring-new-shapira\"}\n",
      "> 2025-05-15 09:06:34,074 [info] Or click for UI: {\"ui_url\":\"https://dashboard.default-tenant.app.innovation-dev.iguazio-cd2.com/mlprojects/llm-monitoring-new-shapira/jobs/monitor-jobs/generate-ds-generate-ds/29babc6796c64e06ba37dea3609bf962/overview\"}\n",
      "> 2025-05-15 09:06:34,075 [info] Run execution finished: {\"name\":\"generate-ds-generate-ds\",\"status\":\"completed\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "\n",
       "  // Get the base URL of the current notebook\n",
       "  var baseUrl = window.location.origin;\n",
       "\n",
       "  // Construct the full URL\n",
       "  var fullUrl = new URL(el.title, baseUrl).href;\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = fullUrl\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (fullUrl.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", fullUrl);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = fullUrl;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>state</th>\n",
       "      <th>kind</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>llm-monitoring-new-shapira</td>\n",
       "      <td><div title=\"29babc6796c64e06ba37dea3609bf962\"><a href=\"https://dashboard.default-tenant.app.innovation-dev.iguazio-cd2.com/mlprojects/llm-monitoring-new-shapira/jobs/monitor/29babc6796c64e06ba37dea3609bf962/overview\" target=\"_blank\" >...609bf962</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>May 15 08:57:24</td>\n",
       "      <td>2025-05-15 09:06:34.068517+00:00</td>\n",
       "      <td>completed</td>\n",
       "      <td>run</td>\n",
       "      <td>generate-ds-generate-ds</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=shapira</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=shapira</div><div class=\"dictlist\">mlrun/client_version=1.8.0-rc45</div><div class=\"dictlist\">mlrun/client_python_version=3.9.22</div><div class=\"dictlist\">host=generate-ds-generate-ds-dn5nf</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">input_ds=store://datasets/llm-monitoring-new-shapira/restrict_to_banking_deepeval</div><div class=\"dictlist\">hf_repo_id=None</div></td>\n",
       "      <td></td>\n",
       "      <td><div title=\"v3io:///projects/llm-monitoring-new-shapira/artifacts/generate-ds-generate-ds/0/new-train-ds.parquet\">new-train-ds</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultfff0922a-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultfff0922a-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultfff0922a\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultfff0922a-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> > to track results use the .show() or .logs() methods  or <a href=\"https://dashboard.default-tenant.app.innovation-dev.iguazio-cd2.com/mlprojects/llm-monitoring-new-shapira/jobs/monitor-jobs/generate-ds-generate-ds/29babc6796c64e06ba37dea3609bf962/overview\" target=\"_blank\">click here</a> to open in UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 09:06:43,223 [info] Run execution finished: {\"name\":\"generate-ds-generate-ds\",\"status\":\"completed\"}\n"
     ]
    }
   ],
   "source": [
    "ret = project.run_function(\n",
    "    function=\"generate-ds\",\n",
    "    handler=\"generate_ds\",\n",
    "    params={\"input_ds\": input_ds,\"hf_repo_id\":None},\n",
    "    outputs=[\"new-train-ds\", \"dataset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "994cb3cc-92aa-4ce1-9c0b-0dfe5a8d136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new-train-ds': 'store://datasets/llm-monitoring-new-shapira/generate-ds-generate-ds_new-train-ds:latest@29babc6796c64e06ba37dea3609bf962^1c34cd32cb7f2982ee27cfd2ac346b1ff84afbc0'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0767dea-5cd2-4a9d-ac08-a418357b916b",
   "metadata": {},
   "source": [
    "Now we have a new dataset for the model tuning stored in HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c064094-0739-4180-93a3-4873f186f995",
   "metadata": {},
   "source": [
    "### 4.2. Fine-tune the Model\n",
    "\n",
    "Now, it's time to fine-tune the model using the ORPO algorithm, so that the model only answers the banking-related questions.\n",
    "\n",
    "[ORPO](https://arxiv.org/abs/2403.07691) is a new method designed to simplify and improve the process of fine-tuning language models to align with user preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556c120-85b1-4ff5-9395-949ea4a50644",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#build the train function image \n",
    "train_func = project.build_function(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105b3a2-77bd-450e-a01c-10e2a424862f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "project.run_function(\n",
    "    function=\"train\",\n",
    "    params={\n",
    "        \"dataset\": \"mlrun/banking-orpo-opt\",\n",
    "        \"base_model\": \"google/gemma-2b\",\n",
    "        \"new_model\": \"mlrun/gemma-2b-bank-v0.2\",\n",
    "        \"device\": \"cuda:0\",\n",
    "    },\n",
    "    handler=\"train\",\n",
    "    outputs=[\"model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15032f46-9dfc-4d88-87c7-610d26189f9e",
   "metadata": {},
   "source": [
    "### 4.3. Check the Performance of the Fine-tuned Model\n",
    "\n",
    "Now load and deploy the trained model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbac65b0-76ff-419f-910a-6fb856b212f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 09:40:00,496 [info] Model google-gemma-2b already exists, updating it.\n"
     ]
    }
   ],
   "source": [
    "serving_function.add_model(\n",
    "    base_model,\n",
    "    class_name=\"LLMModelServer\",\n",
    "    llm_type=\"HuggingFace\",\n",
    "    model_name=\"google/gemma-2b\",\n",
    "    adapter=\"mlrun/gemma-2b-bank-v0.2\",\n",
    "    model_path=f\"store://models/{project.name}/{base_model}:latest\",\n",
    "    generate_kwargs={\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.9,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"max_length\": 80,\n",
    "    },\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "serving_function.set_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3364b62-8897-4037-832b-51a27490fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 09:40:01,933 [info] Starting remote function deploy\n",
      "2025-05-15 09:40:02  (info) Deploying function\n",
      "2025-05-15 09:40:02  (info) Building\n",
      "2025-05-15 09:40:02  (info) Staging files and preparing base images\n",
      "2025-05-15 09:40:02  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2025-05-15 09:40:02  (info) Building processor image\n",
      "2025-05-15 09:44:28  (info) Build complete\n",
      "2025-05-15 09:46:38  (info) Function deploy complete\n",
      "> 2025-05-15 09:46:45,220 [info] Model endpoint creation task completed with state succeeded\n",
      "> 2025-05-15 09:46:45,220 [info] Successfully deployed function: {\"external_invocation_urls\":[\"llm-monitoring-new-shapira-llm-server.default-tenant.app.innovation-dev.iguazio-cd2.com/\"],\"internal_invocation_urls\":[\"nuclio-llm-monitoring-new-shapira-llm-server.default-tenant.svc.cluster.local:8080\"]}\n"
     ]
    }
   ],
   "source": [
    "deployment = serving_function.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cf2a5-d489-4747-9c39-0645be0362d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(20):\n",
    "    question_model(\n",
    "        questions=example_questions,\n",
    "        serving_function=serving_function,\n",
    "        base_model=base_model,\n",
    "    )\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815b08b-d9de-4499-994f-9139b104954f",
   "metadata": {},
   "source": [
    "The Grafana model monitoring page shows a high pass rate and a high guardrails score:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a549dc-d19a-4895-a837-89c52cd3791f",
   "metadata": {},
   "source": [
    "![](./images/grafana_after.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721119e-ce10-47c7-a62f-99bc2c334ea0",
   "metadata": {},
   "source": [
    "### 4.4 Evaluate the model using DeepEval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f2e7d-2d43-4548-bcda-6fd987c6dc35",
   "metadata": {},
   "source": [
    "Again, test the fine tuned model's performance using DeepEval:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452db891-cefd-4489-8423-048b6e3a2f82",
   "metadata": {},
   "source": [
    "#### Banking related question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22bd473e-e713-4745-9a81-8a41a453f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 09:53:29,612 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-llm-monitoring-new-shapira-llm-server.default-tenant.svc.cluster.local:8080/v2/models/google-gemma-2b/infer\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"What is a bank mortgage?\"\n",
    "ret = serving_function.invoke(\n",
    "    path=f\"/v2/models/{base_model}/infer\",\n",
    "    body={\"inputs\": [question]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61ff6c40-b9e4-4c1c-a230-1f466c1b3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A bank mortgage is a type of loan where a lender, typically a bank, provides money to buy a home. The borrower pledges the home as collateral for the loan, meaning if the borrower defaults on the loan, the lender can repossess and sell the home to recover its loan.\n"
     ]
    }
   ],
   "source": [
    "print(ret['outputs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "668677ff-f6ad-4a97-8b86-0af7b6d773a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:03,  3.99s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response directly and comprehensively answered the question, 'What is a bank mortgage?' without any irrelevant information. You've nailed it with clarity and precision!, error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is a bank mortgage?\n",
      "  - actual output: A bank mortgage is a type of loan where a lender, typically a bank, provides money to buy a home. The borrower pledges the home as collateral for the loan, meaning if the borrower defaults on the loan, the lender can repossess and sell the home to recover its loan.\n",
      "  - expected output: A mortgage is a loan used to purchase a house or other real estate.\n",
      "  - context: None\n",
      "  - retrieval context: ['A mortgage is a banking related term']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_case1 = LLMTestCase(\n",
    "    input=question,\n",
    "    actual_output=ret['outputs'][0],\n",
    "    expected_output=\"A mortgage is a loan used to purchase a house or other real estate.\",\n",
    "    retrieval_context=[\"A mortgage is a banking related term\"]\n",
    ")\n",
    "\n",
    "answer_relevancy_metric1 = AnswerRelevancyMetric(threshold=0.5)\n",
    "\n",
    "results1 = evaluate(test_cases=[test_case1], metrics=[answer_relevancy_metric1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe8c26-8aff-427c-b238-de12d7238646",
   "metadata": {},
   "source": [
    "#### Banking non-related question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ce08612-ebec-482d-a043-d17144ed2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-05-15 09:53:37,348 [info] Invoking function: {\"method\":\"POST\",\"path\":\"http://nuclio-llm-monitoring-new-shapira-llm-server.default-tenant.svc.cluster.local:8080/v2/models/google-gemma-2b/infer\"}\n"
     ]
    }
   ],
   "source": [
    "question = \"Who painted the Mona Lisa?\"\n",
    "ret = serving_function.invoke(\n",
    "    path=f\"/v2/models/{base_model}/infer\",\n",
    "    body={\"inputs\": [question]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f12313d-754d-4608-9680-da6e0bbcb761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\n"
     ]
    }
   ],
   "source": [
    "print(ret['outputs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d6f38e7-44b2-40fc-8b94-c157fc0e3719",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case2 = LLMTestCase(\n",
    "    input=question,\n",
    "    actual_output=ret['outputs'][0],\n",
    "    expected_output=\"As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\",\n",
    "    context=[\"This is a banking agent that allowed to talk on banking related issues only.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c38ff582-efe0-4247-89f0-18c9d86ee3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_relevancy_metric2 = HallucinationMetric(threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be3298fd-9c61-48fa-a85c-e170528fc742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |██████████|100% (1/1) [Time Taken: 00:02,  2.72s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output perfectly aligns with the context without any contradictions, indicating no hallucinations in the information provided., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Who painted the Mona Lisa?\n",
      "  - actual output: As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\n",
      "  - expected output: As a banking agent, I am not allowed to talk on this subject. Is there anything else I can help with?\n",
      "  - context: ['This is a banking agent that allowed to talk on banking related issues only.']\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Hallucination: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Tests finished 🎉! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Tests finished 🎉! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "✨👀 Looking for a place for your LLM test data to live 🏡❤️ ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results2 = evaluate(test_cases=[test_case2], metrics=[answer_relevancy_metric2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8b2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-demo",
   "language": "python",
   "name": "conda-env-.conda-new-demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
